{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferencing SSD ONNX model using ONNX Runtime Server\n",
    "\n",
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License.\n",
    "\n",
    "SSD is a state-of-the-art object detection model that enables users to identify individual objects in an image, and place bounding boxes around them.\n",
    "\n",
    "This tutorial uses the Open Neural Network eXchange (ONNX) machine learning model format to show the simplest way to take a pretrained SSD model and start experimenting with object detection. To run through this notebook, you'll need a few dependencies that you can install with the commands below.\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "NumPy for data data manipulation:\n",
    "\n",
    "1) pip install numpy\n",
    "\n",
    "PIL and Matplotlib for raw image manipulation and inline display:\n",
    "\n",
    "2) pip install pillow\n",
    "\n",
    "3) pip install matplotlib\n",
    "\n",
    "## Pre-requisites to run the notebook\n",
    "\n",
    "1) Please download the SSD ONNX model (ssd.onnx) file from [here](https://onnxzoo.blob.core.windows.net/models/opset_10/ssd/ssd.onnx)\n",
    "\n",
    "For example, you could do `wget https://onnxzoo.blob.core.windows.net/models/opset_10/ssd/ssd.onnx` if you have `wget` installed, or you could download the model directly by visiting the referenced URL. \n",
    "\n",
    "2) Please download the ONNXRuntime Server image:\n",
    "\n",
    "`sudo docker pull mcr.microsoft.com/onnxruntime/server`\n",
    "\n",
    "3) In the same folder as the downloaded `ssd.onnx` file, please run:\n",
    "\n",
    "`sudo docker run -it -v $(pwd):$(pwd) -e MODEL_ABSOLUTE_PATH=$(pwd)/ssd.onnx -p 9001:8001 mcr.microsoft.com/onnxruntime/server` on Linux. On Windows, you must use WSL. \n",
    "\n",
    "(In case of errors like port already allocated etc., please only change the number 9001 to something else (keeping 8001 as is). Please remember the changed port number as it will be be needed to modify the URL where the HTTP request is actually sent. Instructions will be present in python comments in the appropriate Jupyter cell.) \n",
    "\n",
    "## Some additional information\n",
    "\n",
    "There are 2 proto files (*.proto) and the corresponding compiled source code files (*__pb2.py) accompanying this notebook. These were [compiled using protoc](https://developers.google.com/protocol-buffers/docs/pythontutorial). For more documentaion regarding ONNX Runtime server (and predict.proto), please visit [this](https://github.com/microsoft/onnxruntime/blob/master/docs/) page and view the contents of `ONNX_Runtime_Server_Usage.md`.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some dependency modules that we are going to need to run the SSD model\n",
    "\n",
    "import numpy as np\n",
    "import predict_pb2\n",
    "import onnx_ml_pb2\n",
    "import requests\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'assets/blueangels.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d8f2d15a095c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"assets/blueangels.jpg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBILINEAR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hasesh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2650\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2651\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2652\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2653\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'assets/blueangels.jpg'"
     ]
    }
   ],
   "source": [
    "# Load the raw image\n",
    "\n",
    "input_shape = (1, 3, 1200, 1200)\n",
    "img = Image.open(\"assets/blueangels.jpg\")\n",
    "img = img.resize((1200, 1200), Image.BILINEAR)\n",
    "\n",
    "# Let us see what the input image looks like\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess and normalize the image\n",
    "\n",
    "img_data = np.array(img)\n",
    "img_data = np.transpose(img_data, [2, 0, 1])\n",
    "img_data = np.expand_dims(img_data, 0)\n",
    "mean_vec = np.array([0.485, 0.456, 0.406])\n",
    "stddev_vec = np.array([0.229, 0.224, 0.225])\n",
    "norm_img_data = np.zeros(img_data.shape).astype('float32')\n",
    "for i in range(img_data.shape[1]):\n",
    "    norm_img_data[:,i,:,:] = (img_data[:,i,:,:]/255 - mean_vec[i]) / stddev_vec[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create request message to be sent to the ORT server\n",
    "\n",
    "input_tensor = onnx_ml_pb2.TensorProto()\n",
    "input_tensor.dims.extend(norm_img_data.shape)\n",
    "input_tensor.data_type = 1\n",
    "input_tensor.raw_data = norm_img_data.tobytes()\n",
    "\n",
    "request_message = predict_pb2.PredictRequest()\n",
    "request_message.inputs[\"image\"].data_type = input_tensor.data_type\n",
    "request_message.inputs[\"image\"].dims.extend(input_tensor.dims)\n",
    "request_message.inputs[\"image\"].raw_data = input_tensor.raw_data\n",
    "\n",
    "content_type_headers = ['application/x-protobuf', 'application/octet-stream', 'application/vnd.google.protobuf']\n",
    "\n",
    "for h in content_type_headers:\n",
    "    request_headers = {\n",
    "        'Content-Type': h,\n",
    "        'Accept': 'application/x-protobuf'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference run using ORT server\n",
    "# Change the number 9001 to the appropriate port number if you had changed it during ORT Server docker instantiation\n",
    "\n",
    "PORT_NUMBER = 9010 # Change if needed\n",
    "inference_url = \"http://10.161.19.27:\" + str(PORT_NUMBER) + \"/v1/models/ssd/versions/1:predict\"\n",
    "response = requests.post(inference_url, headers=request_headers, data=request_message.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse response message\n",
    "\n",
    "response_message = predict_pb2.PredictResponse()\n",
    "response_message.ParseFromString(response.content)\n",
    "\n",
    "bboxes = np.frombuffer(response_message.outputs['bboxes'].raw_data, dtype=np.float32)\n",
    "labels = np.frombuffer(response_message.outputs['labels'].raw_data, dtype=np.int64)\n",
    "scores = np.frombuffer(response_message.outputs['scores'].raw_data, dtype=np.float32)\n",
    "\n",
    "print('Boxes shape:', response_message.outputs['bboxes'].dims)\n",
    "print('Labels shape:', response_message.outputs['labels'].dims)\n",
    "print('Scores shape:', response_message.outputs['scores'].dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display image with bounding boxes and appropriate class \n",
    "\n",
    "# Parse the list of class labels\n",
    "classes = [line.rstrip('\\n') for line in open('assets/coco_classes.txt')]\n",
    "\n",
    "# Plot the bounding boxes on the image\n",
    "plt.figure()\n",
    "fig, ax = plt.subplots(1, figsize=(12,9))\n",
    "ax.imshow(img)\n",
    "\n",
    "resized_width = 1200  # we resized the original image, remember ? \n",
    "resized_height = 1200\n",
    "num_boxes = 6 # we limit displaying to just 10 boxes to avoid clogging the result image with boxes\n",
    "               # The results are already sorted based on box confidences, so we just pick top N boxes without sorting\n",
    "    \n",
    "for c in range(num_boxes):    \n",
    "    base_index = c * 4\n",
    "    y1, x1, y2, x2 = bboxes[base_index] * resized_height, bboxes[base_index + 1] * resized_width, bboxes[base_index + 2] * resized_height, bboxes[base_index + 3] * resized_width \n",
    "    color = 'blue'\n",
    "    box_h = (y2 - y1)\n",
    "    box_w = (x2 - x1)\n",
    "    bbox = patches.Rectangle((y1, x1), box_h, box_w, linewidth=2, edgecolor=color, facecolor='none')\n",
    "    ax.add_patch(bbox)\n",
    "    plt.text(y1, x1, s=classes[labels[c] - 1], color='white', verticalalignment='top', bbox={'color': color, 'pad': 0})\n",
    "plt.axis('off')\n",
    "\n",
    "# Save image\n",
    "plt.savefig(\"result.jpg\", bbox_inches='tight', pad_inches=0.0)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
